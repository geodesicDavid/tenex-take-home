# Story 3.2: Frontend Chat Response Handling

## Status

Approved

## Story

**As a** user,
**I want** to see the agent's response appear in the chat window in real-time,
**so that** I can have a natural and engaging conversation with the cal agent.

## Acceptance Criteria

1. The frontend is updated to handle the streamed response from the `/api/chat` endpoint.
2. A loading indicator is displayed in the chat history immediately after a message is sent, indicating the agent is "thinking."
3. The agent's response appears in the chat history as it is being generated, creating a "typing" effect.
4. The final, complete response from the agent is clearly and correctly displayed in the chat history.

## Tasks / Subtasks

### Streaming Response Handling

- [x] Implement streaming response client (AC: 1)
  - [x] Update chat service to handle streaming responses
  - [x] Create streaming data parser for response chunks
  - [x] Implement proper connection handling for streaming
  - [x] Add error handling for streaming failures
- [x] Enhance message state management (AC: 1, 3)
  - [x] Update `useChatMessages` hook to handle streaming
  - [x] Add partial message state for typing effect
  - [x] Implement message completion detection
  - [x] Handle streaming disconnections gracefully

### Loading and Thinking States

- [x] Create loading indicator component (AC: 2)
  - [x] Design thinking/loading animation with Material-UI
  - [x] Implement skeleton or typing indicator
  - [x] Add proper accessibility attributes
  - [x] Style to match chat interface theme
- [x] Integrate loading states (AC: 2)
  - [x] Add loading state to chat message flow
  - [x] Show loading indicator after message send
  - [x] Hide loading when streaming starts
  - [x] Handle loading state transitions smoothly

### Real-time Message Display

- [x] Implement typing effect (AC: 3)
  - [x] Create character-by-character display animation
  - [x] Add smooth scrolling during typing
  - [x] Implement proper text flow and word wrapping
  - [x] Handle streaming speed variations
- [x] Enhance message list component (AC: 3, 4)
  - [x] Update `ChatMessageList` to handle streaming messages
  - [x] Add visual distinction for partial vs complete messages
  - [x] Implement proper message ordering and timestamps
  - [x] Add completion animations and transitions

### Error Handling and Fallbacks

- [x] Handle streaming errors (AC: 4)
  - [x] Implement error boundaries for streaming failures
  - [x] Add retry mechanism for failed streams
  - [x] Show user-friendly error messages
  - [x] Fallback to non-streaming response handling
- [x] Ensure message consistency (AC: 4)
  - [x] Validate complete message integrity
  - [x] Handle message corruption or truncation
  - [x] Implement message recovery mechanisms
  - [x] Add proper message state persistence

## Dev Notes

### Previous Story Insights

This story depends on multiple previous stories:

- Story 3.1 (Backend LLM Integration) provides the streaming `/api/chat` endpoint
- Story 2.4 (Frontend Chat Interface & Backend Hook) provides the base chat interface
- Story 2.2 (Frontend Main Application Layout) provides the ChatContainer
  [Source: docs/stories/3.1.backend-llm-integration.story.md, docs/stories/2.4.frontend-chat-interface-backend-hook.story.md, docs/stories/2.2.frontend-main-application-layout.story.md]

### Data Models

Enhanced ChatMessage with streaming state [Source: architecture/data-models.md]:

```typescript
interface ChatMessage {
  id: string;
  text: string;
  sender: "user" | "agent";
  timestamp: Date;
  isStreaming?: boolean; // New: Indicates if message is still being streamed
  isComplete?: boolean; // New: Indicates if streaming is complete
  error?: string; // New: Error message if streaming failed
}
```

Streaming response data (new for this story):

```typescript
interface StreamingChunk {
  id: string;
  content: string;
  isComplete: boolean;
  error?: string;
}
```

### API Specifications

Enhanced chat service for streaming [Source: architecture/frontend-architecture.md#Service-Example]:

```typescript
export const sendMessageStreaming = async (
  message: string,
  onChunk: (chunk: StreamingChunk) => void,
): Promise<void> => {
  const response = await fetch("/api/chat", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ message }),
  });

  const reader = response.body?.getReader();
  if (!reader) throw new Error("Streaming not supported");

  // Handle streaming response chunks
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = new TextDecoder().decode(value);
    const parsedChunk = JSON.parse(chunk);
    onChunk(parsedChunk);
  }
};
```

### Component Specifications

Frontend: Enhanced ChatComponent [Source: architecture/components.md#Frontend-ChatComponent]:

- **Responsibility**: Provides main chat interface with real-time streaming responses
- **Key Interfaces**: Renders chat history with typing effects, handles streaming responses
- **Dependencies**: Backend: ChatService (streaming), Enhanced useChatMessages hook
- **Technology Stack**: React, Material-UI, Streaming API client

New: StreamingMessageItem [Source: architecture/components.md#Frontend-StreamingMessageItem]:

- **Responsibility**: Handles individual message display with streaming effects
- **Key Interfaces**: Typing animation, loading states, error display
- **Dependencies**: ChatMessage model with streaming state
- **Technology Stack**: React, Material-UI, CSS animations

New: LoadingIndicator [Source: architecture/components.md#Frontend-LoadingIndicator]:

- **Responsibility**: Shows agent thinking/loading state
- **Key Interfaces**: Animated loading indicator with accessibility
- **Dependencies**: Material-UI components
- **Technology Stack**: React, Material-UI, CSS animations

### File Locations

Based on unified project structure [Source: architecture/unified-project-structure.md]:

- Enhanced chat component: `apps/web/src/components/ChatComponent.tsx` (modify)
- Streaming message item: `apps/web/src/components/StreamingMessageItem.tsx` (new)
- Loading indicator: `apps/web/src/components/LoadingIndicator.tsx` (new)
- Enhanced chat hook: `apps/web/src/hooks/useChatMessages.ts` (modify)
- Enhanced chat service: `apps/web/src/services/chatService.ts` (modify)
- Streaming utilities: `apps/web/src/utils/streaming.ts` (new)
- Enhanced types: `packages/shared/src/chat.ts` (enhance)
- Chat container: `apps/web/src/components/layout/ChatContainer.tsx` (enhance)

### Testing Requirements

Based on testing strategy [Source: architecture/testing-strategy.md]:

- Frontend Tests: `apps/web/src/__tests__/` (Jest & React Testing Library)
- Required tests:
  - Streaming response handling tests
  - Loading state management tests
  - Typing effect animation tests
  - Error handling and fallback tests
  - Message state persistence tests
  - Component rendering and interaction tests
  - Accessibility tests for loading indicators

### Technical Constraints

- Must use React 18.x with TypeScript [Source: architecture/tech-stack.md]
- Must use Material-UI 5.x for components [Source: architecture/tech-stack.md]
- Must handle streaming responses with proper error handling [Source: epic requirements]
- Must implement typing effect with smooth animations [Source: epic requirements]
- Must use existing authentication context [Source: docs/stories/1.3.frontend-login-interface.story.md]
- Must implement proper accessibility for loading states [Source: architecture/coding-standards.md#Accessibility]
- Must use React hooks for state management [Source: architecture/frontend-architecture.md#State-Management-Patterns]
- Must integrate with existing ChatContainer from Story 2.2
- Component naming must follow PascalCase convention [Source: architecture/coding-standards.md#Naming-Conventions]

## Testing

- Frontend test location: `apps/web/src/__tests__/`
- Test standards: Follow testing patterns with Jest & React Testing Library
- Specific requirements:
  - Mock streaming responses for testing
  - Test loading state transitions and animations
  - Test typing effect and character-by-character display
  - Test error handling and fallback mechanisms
  - Test message state management during streaming
  - Test accessibility of loading indicators
  - Test component re-rendering during streaming
  - Test integration with backend streaming endpoint

## Change Log

| Date       | Version | Description         | Author             |
| ---------- | ------- | ------------------- | ------------------ |
| 2025-09-02 | 1.0     | Initial story draft | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used

Claude 3.5 Sonnet (2024-10-22)

### Debug Log References

No debug logs generated during implementation.

### Completion Notes List

- Successfully implemented streaming response handling for chat messages
- Created LoadingIndicator component with Material-UI styling and accessibility
- Enhanced ChatMessageItem with typing animation and visual distinction for streaming states
- Updated useChatMessages hook to handle streaming chunks and message updates
- Added comprehensive error handling for streaming failures
- All TypeScript compilation errors resolved
- Build process completes successfully

### File List

- `packages/shared/src/chat.ts` - Enhanced with streaming types (StreamingChunk, StreamingMessage, enhanced ChatMessage)
- `apps/web/src/services/chatService.ts` - Added sendMessageStreaming function with SSE handling
- `apps/web/src/hooks/useChatMessages.ts` - Updated to handle streaming messages and partial updates
- `apps/web/src/components/LoadingIndicator.tsx` - New component for showing loading/thinking states
- `apps/web/src/components/ChatMessageList.tsx` - Updated to handle loading states and streaming messages
- `apps/web/src/components/ChatMessageItem.tsx` - Enhanced with typing effects and streaming state visualization
- `apps/web/src/components/ChatComponent.tsx` - Updated to pass loading state to message list

## QA Results
